{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1liREoQzVs85oeorJD1_29VEpEHykWYCL",
      "authorship_tag": "ABX9TyMbQYw/Y8bE/bl2NGLLaJUv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WVadim/DiscretizationLayer/blob/master/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVI2kglddUOb"
      },
      "source": [
        "import keras\n",
        "from keras.preprocessing.image import load_img, ImageDataGenerator\n",
        "from keras.applications.nasnet import NASNetMobile\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import BatchNormalization, Dense, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, AveragePooling2D, GlobalMaxPool2D, MaxPool2D, GaussianNoise, SeparableConv2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard, ReduceLROnPlateau, ModelCheckpoint, LearningRateScheduler\n",
        "\n",
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "from shutil import copyfile, rmtree\n",
        "from os import listdir, walk, mkdir, rmdir, remove\n",
        "from os.path import isfile, join, isdir, exists\n",
        "\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ci7fLUd7T0Cf"
      },
      "source": [
        "Library with pretrained face recognition models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNwd_We90rTp",
        "outputId": "9c6b3b99-31e8-4a00-9428-dc205cedc990"
      },
      "source": [
        "!pip install git+https://github.com/rcmalli/keras-vggface.git\n",
        "!pip install keras_applications"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/rcmalli/keras-vggface.git\n",
            "  Cloning https://github.com/rcmalli/keras-vggface.git to /tmp/pip-req-build-wls29nni\n",
            "  Running command git clone -q https://github.com/rcmalli/keras-vggface.git /tmp/pip-req-build-wls29nni\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.10.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (7.0.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (2.4.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras-vggface==0.6) (3.13)\n",
            "Building wheels for collected packages: keras-vggface\n",
            "  Building wheel for keras-vggface (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-vggface: filename=keras_vggface-0.6-cp36-none-any.whl size=8310 sha256=51d4aa36bc72d704309cc3efdcbda855741e28ac3575bcaf7b0336a02edc173b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4thc6ovv/wheels/36/07/46/06c25ce8e9cd396dabe151ea1d8a2bc28dafcb11321c1f3a6d\n",
            "Successfully built keras-vggface\n",
            "Installing collected packages: keras-vggface\n",
            "Successfully installed keras-vggface-0.6\n",
            "Collecting keras_applications\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras_applications) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras_applications) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->keras_applications) (1.15.0)\n",
            "Installing collected packages: keras-applications\n",
            "Successfully installed keras-applications-1.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUK-p6Dv0_BG"
      },
      "source": [
        "from keras_vggface.vggface import VGGFace"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m194Uj37-jC"
      },
      "source": [
        "Restructure the dataset to use keras built-in preprocessing. Split to directories just because navigation is simplier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCqQS5wTQ7YD"
      },
      "source": [
        "data_path = '/content/drive/MyDrive/dataset/'\n",
        "images_path = join(data_path, 'data_for_test')\n",
        "structured_data_path = join(data_path, 'data_structured')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1nV5tWgVga5"
      },
      "source": [
        "with open(join(data_path, 'labels_for_test.json'), 'r') as f:\n",
        "  labels = json.load(f)\n",
        "\n",
        "classes = list(set(labels.values()))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9An2s-DdnE9"
      },
      "source": [
        "if exists(structured_data_path):\n",
        "  if isdir(structured_data_path):\n",
        "    rmtree(structured_data_path)\n",
        "  else:\n",
        "    remove(structured_data_path)\n",
        "\n",
        "mkdir(structured_data_path)\n",
        "\n",
        "classes = set(labels.values())\n",
        "for cl in classes:\n",
        "  dir_path = join(structured_data_path, cl)\n",
        "  mkdir(dir_path)\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFhatM-P2YdI",
        "outputId": "8b0ac4fd-84df-44db-b2f8-0cebc9d4defe"
      },
      "source": [
        "walk_result = next(walk(images_path))[2:][0]\n",
        "\n",
        "for filename in tqdm(walk_result):\n",
        "  cl = labels[filename]\n",
        "  new_file_path = join(join(structured_data_path, cl), filename)\n",
        "  if exists(new_file_path):\n",
        "    continue\n",
        "  old_file_path = join(images_path, filename)\n",
        "  copyfile(old_file_path, new_file_path)\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2001/2001 [00:00<00:00, 3059.98it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTE3eZ1mTtTY"
      },
      "source": [
        "Some augmentation to increase amount of data, since it's just 2k samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R4Xv8lEwwlA"
      },
      "source": [
        "data_gen = ImageDataGenerator(rescale=1./255,\n",
        "                              rotation_range=15,\n",
        "                              width_shift_range=0.2,\n",
        "                              horizontal_flip=True,\n",
        "                              zoom_range=0.1,\n",
        "                              brightness_range=[0.5,1.0],\n",
        "                              channel_shift_range=10,\n",
        "                              validation_split=0.25)\n",
        "val_data_gen = ImageDataGenerator(rescale=1./255, validation_split=0.25)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lvmHXizJmZj"
      },
      "source": [
        "Train VGG that was trained for face recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCzCJHxYwtXU",
        "outputId": "ff28281d-b273-4a8f-b323-ca19e7eabcbc"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "facenet = VGGFace(include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "fn_o = facenet.output\n",
        "# facenet.output.shape == 7, 7, 512\n",
        "x = BatchNormalization()(fn_o)\n",
        "x = SeparableConv2D(256, (3, 3), strides=(1, 1))(x)\n",
        "x = MaxPool2D((2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(.2)(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(.2)(x)\n",
        "x = Dense(8, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=facenet.input, outputs=x)\n",
        "\n",
        "for layer in facenet.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer = 'rmsprop', loss='categorical_crossentropy', metrics=[keras.metrics.CategoricalAccuracy(name=\"acc\"), keras.metrics.TopKCategoricalAccuracy(\n",
        "    k=3, name=\"top_3_acc\")])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/rcmalli/keras-vggface/releases/download/v2.0/rcmalli_vggface_tf_notop_vgg16.h5\n",
            "58916864/58909280 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YI_uC7ioAylh",
        "outputId": "2962eb2a-fcf2-4975-97cc-918ac6610afe"
      },
      "source": [
        "batch_size = 64\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    directory=structured_data_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    seed=27,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = val_data_gen.flow_from_directory(\n",
        "    directory=structured_data_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    seed=27,\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  epoch = epoch % 20\n",
        "  if epoch == 0:\n",
        "    lr = 1e-4\n",
        "  if lr > 1e-4:\n",
        "    lr /= 1.5\n",
        "  return lr\n",
        "\n",
        "callbacks = [ModelCheckpoint(join(data_path, 'best_vgg_model'), save_best_only=True, save_weights_only=True),\n",
        "             LearningRateScheduler(scheduler)]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1504 images belonging to 8 classes.\n",
            "Found 497 images belonging to 8 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRstjRPe4luS",
        "outputId": "035abb29-4918-4464-cdda-7aa7a36da4a5"
      },
      "source": [
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=100,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.samples // batch_size,\n",
        "    callbacks=callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1504 images belonging to 8 classes.\n",
            "Found 497 images belonging to 8 classes.\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 108s 5s/step - loss: 2.0686 - acc: 0.1768 - top_3_acc: 0.4258 - val_loss: 2.0734 - val_acc: 0.1451 - val_top_3_acc: 0.5045\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 2.0461 - acc: 0.1669 - top_3_acc: 0.4822 - val_loss: 2.0679 - val_acc: 0.1786 - val_top_3_acc: 0.5089\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 2.0266 - acc: 0.2251 - top_3_acc: 0.5126 - val_loss: 2.0633 - val_acc: 0.1942 - val_top_3_acc: 0.5156\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 2.0019 - acc: 0.2521 - top_3_acc: 0.5472 - val_loss: 2.0547 - val_acc: 0.2835 - val_top_3_acc: 0.5893\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.9832 - acc: 0.2620 - top_3_acc: 0.5858 - val_loss: 2.0473 - val_acc: 0.2790 - val_top_3_acc: 0.5848\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 105s 5s/step - loss: 1.9559 - acc: 0.2729 - top_3_acc: 0.5666 - val_loss: 2.0371 - val_acc: 0.3013 - val_top_3_acc: 0.6161\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.9417 - acc: 0.2729 - top_3_acc: 0.6004 - val_loss: 2.0235 - val_acc: 0.3125 - val_top_3_acc: 0.6250\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.8931 - acc: 0.3206 - top_3_acc: 0.6143 - val_loss: 2.0104 - val_acc: 0.3237 - val_top_3_acc: 0.6473\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.8674 - acc: 0.3139 - top_3_acc: 0.6262 - val_loss: 1.9905 - val_acc: 0.3415 - val_top_3_acc: 0.6540\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.8480 - acc: 0.3140 - top_3_acc: 0.6307 - val_loss: 1.9658 - val_acc: 0.3661 - val_top_3_acc: 0.7121\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.8384 - acc: 0.3342 - top_3_acc: 0.6699 - val_loss: 1.9412 - val_acc: 0.3460 - val_top_3_acc: 0.7098\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.7673 - acc: 0.3675 - top_3_acc: 0.6937 - val_loss: 1.9118 - val_acc: 0.3482 - val_top_3_acc: 0.7143\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.7550 - acc: 0.3728 - top_3_acc: 0.6772 - val_loss: 1.8911 - val_acc: 0.3683 - val_top_3_acc: 0.7411\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.7414 - acc: 0.3686 - top_3_acc: 0.6997 - val_loss: 1.8463 - val_acc: 0.3996 - val_top_3_acc: 0.7679\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.7008 - acc: 0.3512 - top_3_acc: 0.7326 - val_loss: 1.8028 - val_acc: 0.3973 - val_top_3_acc: 0.7946\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.6656 - acc: 0.3893 - top_3_acc: 0.7409 - val_loss: 1.7641 - val_acc: 0.4152 - val_top_3_acc: 0.8103\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.6509 - acc: 0.3970 - top_3_acc: 0.7564 - val_loss: 1.7249 - val_acc: 0.4196 - val_top_3_acc: 0.8036\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.5931 - acc: 0.4393 - top_3_acc: 0.7542 - val_loss: 1.6930 - val_acc: 0.4241 - val_top_3_acc: 0.8013\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 105s 5s/step - loss: 1.5895 - acc: 0.4275 - top_3_acc: 0.7826 - val_loss: 1.6340 - val_acc: 0.4286 - val_top_3_acc: 0.8214\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.5971 - acc: 0.4032 - top_3_acc: 0.7748 - val_loss: 1.5921 - val_acc: 0.4330 - val_top_3_acc: 0.8393\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.5771 - acc: 0.4406 - top_3_acc: 0.7883 - val_loss: 1.5592 - val_acc: 0.4464 - val_top_3_acc: 0.8415\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.5378 - acc: 0.4282 - top_3_acc: 0.7750 - val_loss: 1.5264 - val_acc: 0.4353 - val_top_3_acc: 0.8371\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.5199 - acc: 0.4409 - top_3_acc: 0.7933 - val_loss: 1.4926 - val_acc: 0.4487 - val_top_3_acc: 0.8504\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.4521 - acc: 0.4803 - top_3_acc: 0.8281 - val_loss: 1.4651 - val_acc: 0.4420 - val_top_3_acc: 0.8393\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.5023 - acc: 0.4310 - top_3_acc: 0.7874 - val_loss: 1.4500 - val_acc: 0.4353 - val_top_3_acc: 0.8438\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.4541 - acc: 0.4649 - top_3_acc: 0.8231 - val_loss: 1.4003 - val_acc: 0.4576 - val_top_3_acc: 0.8527\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.4662 - acc: 0.4470 - top_3_acc: 0.8027 - val_loss: 1.3835 - val_acc: 0.4688 - val_top_3_acc: 0.8438\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.4164 - acc: 0.4757 - top_3_acc: 0.8234 - val_loss: 1.4049 - val_acc: 0.4420 - val_top_3_acc: 0.8393\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.3934 - acc: 0.4867 - top_3_acc: 0.8351 - val_loss: 1.3665 - val_acc: 0.4754 - val_top_3_acc: 0.8393\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.3789 - acc: 0.4839 - top_3_acc: 0.8471 - val_loss: 1.3627 - val_acc: 0.4799 - val_top_3_acc: 0.8304\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.3925 - acc: 0.4706 - top_3_acc: 0.8234 - val_loss: 1.3592 - val_acc: 0.4576 - val_top_3_acc: 0.8438\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.3679 - acc: 0.5073 - top_3_acc: 0.8397 - val_loss: 1.3350 - val_acc: 0.4710 - val_top_3_acc: 0.8527\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.3615 - acc: 0.5130 - top_3_acc: 0.8289 - val_loss: 1.3554 - val_acc: 0.4710 - val_top_3_acc: 0.8415\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.3110 - acc: 0.5202 - top_3_acc: 0.8482 - val_loss: 1.3087 - val_acc: 0.4799 - val_top_3_acc: 0.8504\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.3432 - acc: 0.4916 - top_3_acc: 0.8448 - val_loss: 1.3670 - val_acc: 0.4487 - val_top_3_acc: 0.8504\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.3262 - acc: 0.5180 - top_3_acc: 0.8489 - val_loss: 1.3447 - val_acc: 0.4844 - val_top_3_acc: 0.8571\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.3121 - acc: 0.5210 - top_3_acc: 0.8607 - val_loss: 1.3171 - val_acc: 0.5112 - val_top_3_acc: 0.8527\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 103s 5s/step - loss: 1.3280 - acc: 0.5143 - top_3_acc: 0.8486 - val_loss: 1.3370 - val_acc: 0.4866 - val_top_3_acc: 0.8549\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.3039 - acc: 0.5250 - top_3_acc: 0.8656 - val_loss: 1.3602 - val_acc: 0.4888 - val_top_3_acc: 0.8415\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.2920 - acc: 0.5250 - top_3_acc: 0.8714 - val_loss: 1.3388 - val_acc: 0.4955 - val_top_3_acc: 0.8616\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.2726 - acc: 0.5585 - top_3_acc: 0.8669 - val_loss: 1.3660 - val_acc: 0.4754 - val_top_3_acc: 0.8527\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.2383 - acc: 0.5414 - top_3_acc: 0.8751 - val_loss: 1.3404 - val_acc: 0.4955 - val_top_3_acc: 0.8527\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.2694 - acc: 0.5607 - top_3_acc: 0.8698 - val_loss: 1.3362 - val_acc: 0.4799 - val_top_3_acc: 0.8571\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.2421 - acc: 0.5418 - top_3_acc: 0.8687 - val_loss: 1.3521 - val_acc: 0.4911 - val_top_3_acc: 0.8571\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 105s 5s/step - loss: 1.2109 - acc: 0.5757 - top_3_acc: 0.8855 - val_loss: 1.3133 - val_acc: 0.4866 - val_top_3_acc: 0.8527\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.2219 - acc: 0.5539 - top_3_acc: 0.8778 - val_loss: 1.3238 - val_acc: 0.4978 - val_top_3_acc: 0.8549\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.2084 - acc: 0.5645 - top_3_acc: 0.8884 - val_loss: 1.3241 - val_acc: 0.4933 - val_top_3_acc: 0.8571\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 103s 5s/step - loss: 1.1734 - acc: 0.5782 - top_3_acc: 0.8754 - val_loss: 1.3251 - val_acc: 0.4732 - val_top_3_acc: 0.8638\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.2156 - acc: 0.5687 - top_3_acc: 0.8824 - val_loss: 1.2908 - val_acc: 0.5112 - val_top_3_acc: 0.8571\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.1464 - acc: 0.5951 - top_3_acc: 0.8941 - val_loss: 1.3231 - val_acc: 0.4978 - val_top_3_acc: 0.8549\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 105s 5s/step - loss: 1.1909 - acc: 0.5740 - top_3_acc: 0.8774 - val_loss: 1.3231 - val_acc: 0.5112 - val_top_3_acc: 0.8504\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.1732 - acc: 0.5958 - top_3_acc: 0.8906 - val_loss: 1.3188 - val_acc: 0.5112 - val_top_3_acc: 0.8504\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.1800 - acc: 0.5691 - top_3_acc: 0.8916 - val_loss: 1.3300 - val_acc: 0.4955 - val_top_3_acc: 0.8482\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.1613 - acc: 0.5808 - top_3_acc: 0.8877 - val_loss: 1.3400 - val_acc: 0.5000 - val_top_3_acc: 0.8549\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.1512 - acc: 0.5662 - top_3_acc: 0.8871 - val_loss: 1.3008 - val_acc: 0.5067 - val_top_3_acc: 0.8594\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.1213 - acc: 0.5967 - top_3_acc: 0.9010 - val_loss: 1.3514 - val_acc: 0.4978 - val_top_3_acc: 0.8527\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.1174 - acc: 0.5984 - top_3_acc: 0.8929 - val_loss: 1.3149 - val_acc: 0.5045 - val_top_3_acc: 0.8460\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.1274 - acc: 0.5931 - top_3_acc: 0.9091 - val_loss: 1.3110 - val_acc: 0.5156 - val_top_3_acc: 0.8571\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.0877 - acc: 0.6263 - top_3_acc: 0.9005 - val_loss: 1.3048 - val_acc: 0.5179 - val_top_3_acc: 0.8571\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.0899 - acc: 0.6020 - top_3_acc: 0.9047 - val_loss: 1.3508 - val_acc: 0.5156 - val_top_3_acc: 0.8504\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 103s 5s/step - loss: 1.1149 - acc: 0.5967 - top_3_acc: 0.9059 - val_loss: 1.2851 - val_acc: 0.5335 - val_top_3_acc: 0.8527\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.0872 - acc: 0.6287 - top_3_acc: 0.9045 - val_loss: 1.2897 - val_acc: 0.5290 - val_top_3_acc: 0.8616\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 103s 5s/step - loss: 1.0802 - acc: 0.6281 - top_3_acc: 0.9022 - val_loss: 1.3323 - val_acc: 0.5112 - val_top_3_acc: 0.8504\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 105s 5s/step - loss: 1.0472 - acc: 0.6131 - top_3_acc: 0.9251 - val_loss: 1.3418 - val_acc: 0.5112 - val_top_3_acc: 0.8504\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 103s 5s/step - loss: 1.0595 - acc: 0.6105 - top_3_acc: 0.9114 - val_loss: 1.3346 - val_acc: 0.5246 - val_top_3_acc: 0.8504\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 103s 5s/step - loss: 1.0463 - acc: 0.6360 - top_3_acc: 0.9111 - val_loss: 1.3425 - val_acc: 0.5156 - val_top_3_acc: 0.8571\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.0654 - acc: 0.6331 - top_3_acc: 0.9053 - val_loss: 1.3315 - val_acc: 0.5312 - val_top_3_acc: 0.8571\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 103s 5s/step - loss: 1.0043 - acc: 0.6444 - top_3_acc: 0.9245 - val_loss: 1.3156 - val_acc: 0.5290 - val_top_3_acc: 0.8616\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 103s 5s/step - loss: 1.0439 - acc: 0.6461 - top_3_acc: 0.9207 - val_loss: 1.3612 - val_acc: 0.5223 - val_top_3_acc: 0.8549\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 1.0130 - acc: 0.6370 - top_3_acc: 0.9116 - val_loss: 1.3202 - val_acc: 0.5335 - val_top_3_acc: 0.8549\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 103s 5s/step - loss: 0.9975 - acc: 0.6478 - top_3_acc: 0.9322 - val_loss: 1.3612 - val_acc: 0.5246 - val_top_3_acc: 0.8504\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 103s 5s/step - loss: 1.0171 - acc: 0.6343 - top_3_acc: 0.9187 - val_loss: 1.3480 - val_acc: 0.5246 - val_top_3_acc: 0.8504\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 103s 5s/step - loss: 1.0329 - acc: 0.6240 - top_3_acc: 0.9286 - val_loss: 1.3890 - val_acc: 0.5156 - val_top_3_acc: 0.8415\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 103s 4s/step - loss: 0.9587 - acc: 0.6684 - top_3_acc: 0.9272 - val_loss: 1.3375 - val_acc: 0.5357 - val_top_3_acc: 0.8527\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 103s 5s/step - loss: 0.9775 - acc: 0.6584 - top_3_acc: 0.9332 - val_loss: 1.3523 - val_acc: 0.5223 - val_top_3_acc: 0.8571\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 103s 5s/step - loss: 0.9852 - acc: 0.6552 - top_3_acc: 0.9179 - val_loss: 1.3368 - val_acc: 0.5290 - val_top_3_acc: 0.8705\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 102s 4s/step - loss: 1.0035 - acc: 0.6318 - top_3_acc: 0.9125 - val_loss: 1.3978 - val_acc: 0.5179 - val_top_3_acc: 0.8326\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 102s 4s/step - loss: 0.9723 - acc: 0.6607 - top_3_acc: 0.9163 - val_loss: 1.3924 - val_acc: 0.5268 - val_top_3_acc: 0.8438\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 102s 5s/step - loss: 0.9551 - acc: 0.6828 - top_3_acc: 0.9128 - val_loss: 1.3767 - val_acc: 0.5335 - val_top_3_acc: 0.8527\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 102s 4s/step - loss: 0.9658 - acc: 0.6552 - top_3_acc: 0.9123 - val_loss: 1.3959 - val_acc: 0.5268 - val_top_3_acc: 0.8504\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 102s 4s/step - loss: 0.9302 - acc: 0.6848 - top_3_acc: 0.9366 - val_loss: 1.3677 - val_acc: 0.5379 - val_top_3_acc: 0.8482\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 102s 4s/step - loss: 0.9362 - acc: 0.6766 - top_3_acc: 0.9348 - val_loss: 1.3618 - val_acc: 0.5335 - val_top_3_acc: 0.8571\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 102s 5s/step - loss: 0.9376 - acc: 0.6595 - top_3_acc: 0.9349 - val_loss: 1.4090 - val_acc: 0.5268 - val_top_3_acc: 0.8371\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 102s 4s/step - loss: 0.9668 - acc: 0.6546 - top_3_acc: 0.9348 - val_loss: 1.3263 - val_acc: 0.5424 - val_top_3_acc: 0.8549\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 103s 4s/step - loss: 0.9576 - acc: 0.6602 - top_3_acc: 0.9151 - val_loss: 1.4025 - val_acc: 0.5335 - val_top_3_acc: 0.8460\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 102s 4s/step - loss: 0.9298 - acc: 0.6641 - top_3_acc: 0.9281 - val_loss: 1.3925 - val_acc: 0.5290 - val_top_3_acc: 0.8460\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 103s 5s/step - loss: 0.9630 - acc: 0.6622 - top_3_acc: 0.9091 - val_loss: 1.3809 - val_acc: 0.5424 - val_top_3_acc: 0.8527\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 102s 4s/step - loss: 0.9317 - acc: 0.6653 - top_3_acc: 0.9359 - val_loss: 1.4129 - val_acc: 0.5246 - val_top_3_acc: 0.8371\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 102s 4s/step - loss: 0.8618 - acc: 0.6974 - top_3_acc: 0.9400 - val_loss: 1.4236 - val_acc: 0.5201 - val_top_3_acc: 0.8415\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 0.9081 - acc: 0.6857 - top_3_acc: 0.9401 - val_loss: 1.4147 - val_acc: 0.5156 - val_top_3_acc: 0.8527\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 105s 5s/step - loss: 0.8536 - acc: 0.7134 - top_3_acc: 0.9333 - val_loss: 1.4256 - val_acc: 0.5201 - val_top_3_acc: 0.8393\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 103s 5s/step - loss: 0.8865 - acc: 0.6777 - top_3_acc: 0.9491 - val_loss: 1.4318 - val_acc: 0.5335 - val_top_3_acc: 0.8371\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 0.8781 - acc: 0.7017 - top_3_acc: 0.9335 - val_loss: 1.4056 - val_acc: 0.5402 - val_top_3_acc: 0.8460\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 0.8682 - acc: 0.7059 - top_3_acc: 0.9352 - val_loss: 1.4108 - val_acc: 0.5268 - val_top_3_acc: 0.8527\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 103s 5s/step - loss: 0.8898 - acc: 0.6752 - top_3_acc: 0.9435 - val_loss: 1.3802 - val_acc: 0.5290 - val_top_3_acc: 0.8482\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 0.8595 - acc: 0.6858 - top_3_acc: 0.9434 - val_loss: 1.4129 - val_acc: 0.5312 - val_top_3_acc: 0.8415\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 0.8471 - acc: 0.7051 - top_3_acc: 0.9294 - val_loss: 1.4126 - val_acc: 0.5357 - val_top_3_acc: 0.8460\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 103s 5s/step - loss: 0.8381 - acc: 0.6969 - top_3_acc: 0.9481 - val_loss: 1.4338 - val_acc: 0.5290 - val_top_3_acc: 0.8415\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 104s 5s/step - loss: 0.8275 - acc: 0.7108 - top_3_acc: 0.9439 - val_loss: 1.4318 - val_acc: 0.5312 - val_top_3_acc: 0.8460\n",
            "Epoch 100/100\n",
            "13/23 [===============>..............] - ETA: 34s - loss: 0.8532 - acc: 0.7105 - top_3_acc: 0.9270"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mSpuvNa1xxh",
        "outputId": "b8f4c6e0-8119-4188-9069-c06d8cb10d06"
      },
      "source": [
        "model.load_weights(join(data_path, 'best_vgg_model'))\n",
        "model.evaluate_generator(val_generator)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.314428448677063, 0.5231388211250305, 0.8511066436767578]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyOOwJLDJiPi"
      },
      "source": [
        "Train InceptionV3 for comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTj8Hlby3eu1"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "facenet = keras.applications.InceptionV3(include_top=False, input_shape=(299, 299, 3))\n",
        "\n",
        "fn_o = facenet.output\n",
        "# facenet.output.shape == 5, 5, 2048\n",
        "x = BatchNormalization()(fn_o)\n",
        "x = SeparableConv2D(256, (5, 5), strides=(1, 1))(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(.25)(x)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dropout(.25)(x)\n",
        "x = Dense(32, activation='relu')(x)\n",
        "x = Dense(8, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=facenet.input, outputs=x)\n",
        "\n",
        "for layer in facenet.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer = Adam(lr=5e-4), loss='categorical_crossentropy', metrics=[keras.metrics.CategoricalAccuracy(name=\"acc\"), keras.metrics.TopKCategoricalAccuracy(\n",
        "    k=3, name=\"top_3_acc\")])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ndUXGG8W36ct",
        "outputId": "c83b58fb-d5b1-4e7f-eb6e-80af8442b820"
      },
      "source": [
        "batch_size = 64\n",
        "train_generator = data_gen.flow_from_directory(\n",
        "    directory=structured_data_path,\n",
        "    target_size=(299, 299),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    seed=27,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = val_data_gen.flow_from_directory(\n",
        "    directory=structured_data_path,\n",
        "    target_size=(299, 299),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    seed=27,\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "callbacks = [ModelCheckpoint(join(data_path, 'best_ins_model'), save_best_only=True, save_weights_only=True), \n",
        "             ReduceLROnPlateau(patience=2, min_lr=1e-5, factor=0.5, cooldown=3, verbose=1)]\n",
        "\n",
        "model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,\n",
        "    epochs=100,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.samples // batch_size,\n",
        "    callbacks=callbacks)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1504 images belonging to 8 classes.\n",
            "Found 497 images belonging to 8 classes.\n",
            "Epoch 1/100\n",
            "23/23 [==============================] - 124s 5s/step - loss: 2.0609 - acc: 0.1197 - top_3_acc: 0.4316 - val_loss: 1.9667 - val_acc: 0.2210 - val_top_3_acc: 0.5513\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 117s 5s/step - loss: 1.8809 - acc: 0.3161 - top_3_acc: 0.6394 - val_loss: 1.7288 - val_acc: 0.3616 - val_top_3_acc: 0.6942\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 117s 5s/step - loss: 1.6838 - acc: 0.3596 - top_3_acc: 0.7309 - val_loss: 1.6195 - val_acc: 0.3839 - val_top_3_acc: 0.7277\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 119s 5s/step - loss: 1.5436 - acc: 0.4311 - top_3_acc: 0.7648 - val_loss: 1.4846 - val_acc: 0.4821 - val_top_3_acc: 0.8013\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 117s 5s/step - loss: 1.3940 - acc: 0.4910 - top_3_acc: 0.8161 - val_loss: 1.4647 - val_acc: 0.4397 - val_top_3_acc: 0.7879\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 117s 5s/step - loss: 1.3437 - acc: 0.5353 - top_3_acc: 0.8342 - val_loss: 1.4068 - val_acc: 0.4911 - val_top_3_acc: 0.7924\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 117s 5s/step - loss: 1.1817 - acc: 0.5728 - top_3_acc: 0.8697 - val_loss: 1.3775 - val_acc: 0.4821 - val_top_3_acc: 0.8214\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 117s 5s/step - loss: 1.0910 - acc: 0.6131 - top_3_acc: 0.8900 - val_loss: 1.4155 - val_acc: 0.4911 - val_top_3_acc: 0.7969\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 117s 5s/step - loss: 1.1462 - acc: 0.5830 - top_3_acc: 0.8729 - val_loss: 1.4333 - val_acc: 0.4978 - val_top_3_acc: 0.8036\n",
            "\n",
            "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 117s 5s/step - loss: 0.9892 - acc: 0.6497 - top_3_acc: 0.8912 - val_loss: 1.3003 - val_acc: 0.5402 - val_top_3_acc: 0.8348\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 117s 5s/step - loss: 0.9683 - acc: 0.6618 - top_3_acc: 0.8999 - val_loss: 1.3241 - val_acc: 0.5558 - val_top_3_acc: 0.8326\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 116s 5s/step - loss: 0.9266 - acc: 0.6791 - top_3_acc: 0.9106 - val_loss: 1.3391 - val_acc: 0.5580 - val_top_3_acc: 0.8348\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 116s 5s/step - loss: 0.9101 - acc: 0.6845 - top_3_acc: 0.9076 - val_loss: 1.3996 - val_acc: 0.5424 - val_top_3_acc: 0.8438\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 116s 5s/step - loss: 0.8151 - acc: 0.7223 - top_3_acc: 0.9297 - val_loss: 1.3418 - val_acc: 0.5625 - val_top_3_acc: 0.8460\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 116s 5s/step - loss: 0.8291 - acc: 0.7019 - top_3_acc: 0.9192 - val_loss: 1.4108 - val_acc: 0.5513 - val_top_3_acc: 0.8348\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 115s 5s/step - loss: 0.7695 - acc: 0.7265 - top_3_acc: 0.9468 - val_loss: 1.3465 - val_acc: 0.5670 - val_top_3_acc: 0.8415\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 116s 5s/step - loss: 0.8261 - acc: 0.7187 - top_3_acc: 0.9295 - val_loss: 1.3735 - val_acc: 0.5603 - val_top_3_acc: 0.8281\n",
            "\n",
            "Epoch 00017: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 116s 5s/step - loss: 0.7991 - acc: 0.7229 - top_3_acc: 0.9339 - val_loss: 1.4154 - val_acc: 0.5580 - val_top_3_acc: 0.8304\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 117s 5s/step - loss: 0.7161 - acc: 0.7494 - top_3_acc: 0.9469 - val_loss: 1.3499 - val_acc: 0.5781 - val_top_3_acc: 0.8438\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 115s 5s/step - loss: 0.7104 - acc: 0.7441 - top_3_acc: 0.9527 - val_loss: 1.3645 - val_acc: 0.5647 - val_top_3_acc: 0.8348\n",
            "Epoch 21/100\n",
            "13/23 [===============>..............] - ETA: 38s - loss: 0.6681 - acc: 0.7580 - top_3_acc: 0.9450"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-fd06b9bea8d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     callbacks=callbacks)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}